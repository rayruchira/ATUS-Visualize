{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### In this notebook, we demonstrate how to read and filter the ATUS Well Being Data. \n",
    "\n",
    "\n",
    "1. **Importing the necessary library**:\n",
    "\n",
    "2. **Loading the necessary files**:\n",
    "    - The file path is set to `\"/Users/ruchiraray/Documents/UT Austin/Soc-HHR/lexiconwex2021.csv\"`. Replace this path with the path to your CSV file.\n",
    "\n",
    "3. **Creating a dictionary of activities**:\n",
    "    - A dictionary (`activity_code_dict`) is created from the filtered DataFrame, where the keys are the '6-digit activity code' values, and the corresponding values are the 'Activity' name.\n",
    "\n",
    "4. **Filtering the DataFrame**:\n",
    "    - The DataFrame based on age, income, gender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Loading\n",
    "\n",
    "\n",
    "To start off we first load the dataset, these are the csv file we get from ATUS. We select ATUS Summary as it has time info per activity. We also load lexiconwex2021.csv to map the activity to the 6-digit activity code given by ATUS to get a activity dictionary. This dictionary will be used for further analysis in the project.\n",
    "\n",
    "\n",
    "Replace 'file_path' with the path to the CSV file you want to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file_path.csv' with the path to the CSV file you want to read\n",
    "# file_path = '/Users/ruchiraray/Documents/UT Austin/Soc-HHR/BEHAVIOR1kData/survey_analysis/lexiconwex2022.csv'\n",
    "file_path = \"/Users/ruchiraray/Documents/UT Austin/Soc-HHR/lexiconwex2021.csv\"\n",
    "\n",
    "# Attempt to read the CSV file\n",
    "\n",
    "df = pd.read_csv(file_path, header=0)\n",
    "activity_code_df = df[df['6-digit activity code'].notna()][['6-digit activity code', 'Activity']]\n",
    "\n",
    "activity_code_dict = pd.Series(activity_code_df['Activity'].values, index=activity_code_df['6-digit activity code']).to_dict()\n",
    "print(len(activity_code_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "atus_summary_df = pd.read_csv('/Users/ruchiraray/Documents/UT Austin/Soc-HHR/atussum-2021/atussum_2021.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering \n",
    "\n",
    "We now look into filtering our data by by Sex, Income Range, Age Range, Race, Number of Household Children, to create a susbset we want to work with. We do this similar to ATUS time. Using the filtered datafrae, we take the intersection of ATUS Well Being to get our needed subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The following code blocks perform essential data preprocessing tasks required for our analysis. Each block is responsible for a specific aspect of the data filtering and preparation process:\n",
    "\n",
    "1. **Sex**: This code block maps gender labels to numerical values and filters the dataset based on the selected gender.\n",
    "2. **Income**: This code block maps income codes to income ranges, classifies income levels, and filters the dataset based on income classification. We also see filtering based on on a specified income level.\n",
    "3. **Race**: This code block maps race labels to numerical values and filters the dataset based on the selected race.\n",
    "4. **Age Range**: This code block filters the dataset based on a specified age range.\n",
    "\n",
    "These preprocessing steps are crucial for ensuring that the dataset is accurately filtered and categorized according to the criteria specified in the study.\n",
    "\n",
    "Below, we explain each code block in detail, including its purpose, the variables involved, and the logic applied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Sex Dictionary and Filtering\n",
    "\n",
    "This code block maps gender labels to numerical values and filters the dataset based on the selected gender. \n",
    "\n",
    "- **Variables**:\n",
    "  - `sex_dict`: A dictionary mapping gender labels ('male', 'female') to numerical values (1, 2).\n",
    "  - `sex`: A variable that stores the selected gender. If `sex` is specified, the dataset is filtered based on this value.\n",
    "\n",
    "- **Logic**:\n",
    "  - Check if `sex` is specified.\n",
    "  - If `sex` is specified, convert it to the corresponding numerical value using `sex_dict`.\n",
    "  - Filter the DataFrame to include only rows where the gender matches the specified value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dict = {\n",
    "    'male': 1,\n",
    "    'female': 2\n",
    "}\n",
    "\n",
    "sex=None\n",
    "\n",
    "# Sex\n",
    "\n",
    "\n",
    "if sex:\n",
    "    sex_number = sex_dict[sex]\n",
    "    atus_summary_df=atus_summary_df[atus_summary_df['TESEX'] == sex_number]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Income Mapping and Classification\n",
    "\n",
    "This code block maps income codes to income ranges, classifies income levels, and filters the dataset based on income classification.\n",
    "\n",
    "To start off, we load the ATUS rost data for Number of Household memeber information. We use this information alonh with the poverty line information of 2021 to define bounds of low , mid and high income.\n",
    "\n",
    "Over here , we use income mapping to filter based on the bins set by ATUS, we use income class to filter by our set way of defining low, mid and high income. We also have a third income range, where we filter based on the range. It must be noted that for income range and income class, they are both based on income_mapping as these are the incoe information provided to us by ATUS.\n",
    "\n",
    "\n",
    "#### Variables:\n",
    "- `income_mapping`: A dictionary mapping income codes to income ranges.\n",
    "- `income_class`: A variable that stores the selected income class ('high', 'mid', 'low').\n",
    "\n",
    "#### Logic:\n",
    "1. Load the necessary datasets (`atuscps_df`, `household_members_df`, `thresh_df`).\n",
    "2. Merge datasets to get the number of household members for each respondent.\n",
    "3. Define a function `classify_income` that classifies income based on the income code, number of members, and poverty thresholds.\n",
    "4. Apply the classification function to create an 'Income Classification' column.\n",
    "5. Filter the DataFrame based on the specified income class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/Users/ruchiraray/Documents/UT Austin/Soc-HHR/atusrost-2021/atusrost_2021.csv')\n",
    "\n",
    "# Group by 'TUCASEID' and count the unique 'TULINENO' entries for each 'TUCASEID'\n",
    "household_counts = df.groupby('TUCASEID')['TULINENO'].nunique().reset_index()\n",
    "\n",
    "# Rename columns to reflect the data\n",
    "household_counts.columns = ['TUCASEID', 'Number of Household Members']\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "# household_counts.to_csv('household_members_ATUS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_mapping = {\n",
    "    1:[0,5000],\n",
    "    2:[5000,7499],\n",
    "    3:[7500,9999],\n",
    "    4:[10000,12499],\n",
    "    5:[12500,14999],\n",
    "    6:[15000,19999],\n",
    "    7:[20000,24999],\n",
    "    8:[25000,29999],\n",
    "    9:[30000,34999],\n",
    "    10:[35000,39999],\n",
    "    11:[40000,49999],\n",
    "    12:[50000,59999],\n",
    "    13:[60000,74999],\n",
    "    14:[75000,99999],\n",
    "    15:[100000,149999],\n",
    "    16:[150000,9999999999]\n",
    "}\n",
    "\n",
    "income=None\n",
    "\n",
    "income_class=None\n",
    "#high low mid\n",
    "\n",
    "\n",
    "\n",
    "# Income Claasification by family member threshold + poverty line 2021\n",
    "if income_class:   \n",
    "    # Load the data\n",
    "    atuscps_df = pd.read_csv('/Users/ruchiraray/Documents/UT Austin/Soc-HHR/atuscps-2021/atuscps_2021.csv')\n",
    "    household_members_df = household_counts\n",
    "    # pd.read_csv('/Users/ruchiraray/Documents/UT Austin/Soc-HHR/BEHAVIOR1kData/survey_analysis/household_members_ATUS.csv')\n",
    "    thresh_df = pd.read_csv('/Users/ruchiraray/Documents/UT Austin/Soc-HHR/BEHAVIOR1kData/survey_analysis/thresholds.csv')\n",
    "\n",
    "    # Merge atuscps_df with household_members_df to get the number of members for each household\n",
    "    atuscps_df = atuscps_df.merge(household_members_df, on='TUCASEID')\n",
    "\n",
    "    # Function to classify income based on HEFAMINC, number of members, and thresholds\n",
    "    def classify_income(row, thresh_df):\n",
    "        income_code = row['HEFAMINC']\n",
    "        members = row['Members']\n",
    "        \n",
    "        # Map the income code to a range using income_mapping\n",
    "        lower_limit, upper_limit = income_mapping[income_code]\n",
    "\n",
    "        # Find the appropriate threshold for the number of members\n",
    "        if members >= 9:  # Assuming last row in thresh_df is for 5 and above\n",
    "            thresh_row = thresh_df.iloc[-1]\n",
    "        else:\n",
    "            thresh_row = thresh_df[thresh_df['Size'] == members].iloc[0]\n",
    "\n",
    "        # # Classify income\n",
    "        # if lower_limit==0:\n",
    "        #     return 'low'\n",
    "        # else:\n",
    "        # Determine if it's mid based on the mapping and thresholds\n",
    "        low_thresh = thresh_row['poverty']\n",
    "        high_thresh = thresh_row['high']\n",
    "        if upper_limit <= low_thresh:\n",
    "            return 'low'\n",
    "        elif lower_limit >= high_thresh:\n",
    "            return 'high'\n",
    "        else:\n",
    "            return 'mid'\n",
    "\n",
    "    # Apply the classification function\n",
    "    atuscps_df['Income Classification'] = atuscps_df.apply(classify_income, args=(thresh_df,), axis=1)\n",
    "\n",
    "    atus_summary_df = atus_summary_df.merge(atuscps_df[['TUCASEID', 'Income Classification']], on='TUCASEID', how='left')\n",
    "\n",
    "    atus_summary_df=atus_summary_df[atus_summary_df['Income Classification'] == \"high\"]\n",
    "\n",
    "# Income\n",
    "\n",
    "if income:\n",
    "    # Load the data\n",
    "    atuscps_df = pd.read_csv('/Users/ruchiraray/Documents/UT Austin/Soc-HHR/atuscps-2021/atuscps_2021.csv')\n",
    "\n",
    "    # Merge atussum_df with classified_atuscps_df to get HEFAMINC value\n",
    "    atus_summary_df = atus_summary_df.merge(atuscps_df[['TUCASEID', 'HEFAMINC']], on='TUCASEID', how='left')\n",
    "\n",
    "    # Filter rows where HEFAMINC is 2\n",
    "    atus_summary_df = atus_summary_df[atus_summary_df['HEFAMINC'] == income]\n",
    "\n",
    "\n",
    "\n",
    "# Income Range -custom \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Race Dictionaries and Filtering\n",
    "\n",
    "This code block maps race labels to numerical values and filters the dataset based on the selected race.\n",
    "\n",
    "#### Explanation:\n",
    "\n",
    "#### Variables:\n",
    "- `raceasain_dict` and `race_dict`: Dictionaries mapping race labels to numerical values.\n",
    "- `race_name`: A variable that stores the selected race.\n",
    "\n",
    "#### Logic:\n",
    "1. Check if `race_name` is specified.\n",
    "2. If `race_name` is specified, convert it to the corresponding numerical value using `race_dict`.\n",
    "3. Filter the DataFrame to include only rows where the race matches the specified value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "start_age = 0\n",
    "end_age = 1000\n",
    "\n",
    "\n",
    "raceasain_dict = {\n",
    "    'Asian Indian': 1,\n",
    "    'Chinese': 2,\n",
    "    'Filipino': 3,\n",
    "    'Japanese': 4,\n",
    "    'Korean': 5,\n",
    "    'Vietnamese': 6,\n",
    "    'Other': 7\n",
    "}\n",
    "\n",
    "race_dict = {\n",
    "    'White only': 1,\n",
    "    'Black only': 2,\n",
    "    'American Indian, Alaskan Native only': 3,\n",
    "    'Asian only': 4,\n",
    "    'Hawaiian/Pacific Islander only': 5,\n",
    "    'White-Black': 6,\n",
    "    'White-American Indian': 7,\n",
    "    'White-Asian': 8,\n",
    "    'White-Hawaiian': 9,\n",
    "    'Black-American Indian': 10,\n",
    "    'Black-Asian': 11,\n",
    "    'Black-Hawaiian': 12,\n",
    "    'American Indian-Asian': 13,\n",
    "    'American Indian-Hawaiian': 14,\n",
    "    'Asian-Hawaiian': 15,\n",
    "    'White-Black-American Indian': 16,\n",
    "    'White-Black-Asian': 17,\n",
    "    'White-Black-Hawaiian': 18,\n",
    "    'White-American Indian-Asian': 19,\n",
    "    'White-American Indian-Hawaiian': 20,\n",
    "    'White-Asian-Hawaiian': 21,\n",
    "    'Black-American Indian-Asian': 22,\n",
    "    'White-Black-American Indian-Asian': 23,\n",
    "    'White-American Indian-Asian-Hawaiian': 24,\n",
    "    'Other 3 race combinations': 25,\n",
    "    'Other 4 and 5 race combinations': 26\n",
    "}\n",
    "\n",
    "\n",
    "race_name = None\n",
    "\n",
    "\n",
    "\n",
    "# Race\n",
    "\n",
    "\n",
    "if race_name:\n",
    "    race_number = race_dict[race_name]\n",
    "    atus_summary_df=atus_summary_df[atus_summary_df['PTDTRACE'] == race_number]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Age Range Filtering\n",
    "\n",
    "This code block filters the dataset based on a specified age range.\n",
    "\n",
    "#### Explanation:\n",
    "\n",
    "#### Variables:\n",
    "- `start_age`: The beginning of the age range to filter.\n",
    "- `end_age`: The end of the age range to filter.\n",
    "\n",
    "#### Logic:\n",
    "1. Define the `start_age` and `end_age` variables to specify the age range.\n",
    "2. Filter the DataFrame to include only rows where the age (`TEAGE`) is within the specified range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age Range\n",
    "start_age = 0\n",
    "# int(input(\"Enter the start age: \"))\n",
    "end_age = 1000\n",
    "# int(input(\"Enter the end age: \"))\n",
    "atus_summary_df = atus_summary_df[(atus_summary_df['TEAGE'] >= start_age) & (atus_summary_df['TEAGE'] <= end_age)]\n",
    "\n",
    "\n",
    "\n",
    "# Number of Household Children - no direct way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TUCASEID</th>\n",
       "      <th>TUFINLWGT</th>\n",
       "      <th>TRYHHCHILD</th>\n",
       "      <th>TEAGE</th>\n",
       "      <th>TESEX</th>\n",
       "      <th>PEEDUCA</th>\n",
       "      <th>PTDTRACE</th>\n",
       "      <th>PEHSPNON</th>\n",
       "      <th>GTMETSTA</th>\n",
       "      <th>TELFS</th>\n",
       "      <th>...</th>\n",
       "      <th>t181501</th>\n",
       "      <th>t181599</th>\n",
       "      <th>t181601</th>\n",
       "      <th>t181801</th>\n",
       "      <th>t189999</th>\n",
       "      <th>t500101</th>\n",
       "      <th>t500103</th>\n",
       "      <th>t500105</th>\n",
       "      <th>t500106</th>\n",
       "      <th>t500107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210101210037</td>\n",
       "      <td>7.575483e+06</td>\n",
       "      <td>-1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210101210081</td>\n",
       "      <td>8.737183e+06</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210101210099</td>\n",
       "      <td>3.023910e+07</td>\n",
       "      <td>-1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210101210101</td>\n",
       "      <td>1.116551e+07</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210101210109</td>\n",
       "      <td>6.562833e+06</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9082</th>\n",
       "      <td>20211212212479</td>\n",
       "      <td>3.571728e+07</td>\n",
       "      <td>-1</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9083</th>\n",
       "      <td>20211212212502</td>\n",
       "      <td>1.220601e+07</td>\n",
       "      <td>-1</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9084</th>\n",
       "      <td>20211212212555</td>\n",
       "      <td>4.810168e+06</td>\n",
       "      <td>-1</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>20211212212567</td>\n",
       "      <td>1.138100e+07</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9086</th>\n",
       "      <td>20211212212591</td>\n",
       "      <td>5.919170e+06</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9087 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TUCASEID     TUFINLWGT  TRYHHCHILD  TEAGE  TESEX  PEEDUCA  \\\n",
       "0     20210101210037  7.575483e+06          -1     60      2       39   \n",
       "1     20210101210081  8.737183e+06          10     30      2       42   \n",
       "2     20210101210099  3.023910e+07          -1     43      1       39   \n",
       "3     20210101210101  1.116551e+07          -1     23      1       43   \n",
       "4     20210101210109  6.562833e+06          -1     20      1       40   \n",
       "...              ...           ...         ...    ...    ...      ...   \n",
       "9082  20211212212479  3.571728e+07          -1     56      1       43   \n",
       "9083  20211212212502  1.220601e+07          -1     69      2       44   \n",
       "9084  20211212212555  4.810168e+06          -1     57      1       43   \n",
       "9085  20211212212567  1.138100e+07           6     34      2       43   \n",
       "9086  20211212212591  5.919170e+06           8     46      1       43   \n",
       "\n",
       "      PTDTRACE  PEHSPNON  GTMETSTA  TELFS  ...  t181501  t181599  t181601  \\\n",
       "0            1         2         2      1  ...        0        0        0   \n",
       "1            1         2         1      1  ...        0        0        0   \n",
       "2            1         2         1      1  ...        0        0        0   \n",
       "3            1         2         1      1  ...        0        0        0   \n",
       "4            1         2         1      1  ...        0        0        0   \n",
       "...        ...       ...       ...    ...  ...      ...      ...      ...   \n",
       "9082         1         2         1      2  ...        0        0        0   \n",
       "9083         1         2         1      5  ...        0        0        0   \n",
       "9084         1         2         1      1  ...        0        0        0   \n",
       "9085         1         2         2      1  ...        0        0        0   \n",
       "9086         1         2         1      1  ...       40        0        0   \n",
       "\n",
       "      t181801  t189999  t500101  t500103  t500105  t500106  t500107  \n",
       "0           0        0       75        0        0        0        0  \n",
       "1           0       60      150        0        0        0        0  \n",
       "2           0        0        0        0        0        0        0  \n",
       "3           0        0        0        0        0        0        0  \n",
       "4           0        0        0        0        0        0        0  \n",
       "...       ...      ...      ...      ...      ...      ...      ...  \n",
       "9082        0        0        0        0        0        0        0  \n",
       "9083        0        0        0        0        0        0        0  \n",
       "9084        0        0        0        0        0        0        0  \n",
       "9085        0        0        0        0        0        0        0  \n",
       "9086        0        0        0        0        0        0        0  \n",
       "\n",
       "[9087 rows x 400 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, given our filtered atus summry file, we take the intersection of it with ATUS Well Being to get our needed filtered subset. To do this we merge the 2 dataframes using \"TUCASEID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TUCASEID</th>\n",
       "      <th>TUACTIVITY_N</th>\n",
       "      <th>TEWHERE</th>\n",
       "      <th>TRTCCTOT_LN</th>\n",
       "      <th>TRTCC_LN</th>\n",
       "      <th>TRTCOC_LN</th>\n",
       "      <th>TRTEC_LN</th>\n",
       "      <th>TRTHH_LN</th>\n",
       "      <th>TRTNOHH_LN</th>\n",
       "      <th>TRTOHH_LN</th>\n",
       "      <th>...</th>\n",
       "      <th>WUINTERACT</th>\n",
       "      <th>WUMEANING</th>\n",
       "      <th>WUPAIN</th>\n",
       "      <th>WUPNORD</th>\n",
       "      <th>WUSAD</th>\n",
       "      <th>WUSADORD</th>\n",
       "      <th>WUSTRESS</th>\n",
       "      <th>WUSTRORD</th>\n",
       "      <th>WUTIRED</th>\n",
       "      <th>WUTRDORD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210301210024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210301210024</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210301210024</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210301210094</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210301210094</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20456</th>\n",
       "      <td>20211212212567</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20457</th>\n",
       "      <td>20211212212567</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20458</th>\n",
       "      <td>20211212212591</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20459</th>\n",
       "      <td>20211212212591</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20460</th>\n",
       "      <td>20211212212591</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20461 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TUCASEID  TUACTIVITY_N  TEWHERE  TRTCCTOT_LN  TRTCC_LN  \\\n",
       "0      20210301210024             2        1            0        -1   \n",
       "1      20210301210024             5        7            0        -1   \n",
       "2      20210301210024             7        4            0        -1   \n",
       "3      20210301210094             3       12            0        -1   \n",
       "4      20210301210094             4        2            0        -1   \n",
       "...               ...           ...      ...          ...       ...   \n",
       "20456  20211212212567            11        1           20        20   \n",
       "20457  20211212212567            15        1            0         0   \n",
       "20458  20211212212591             3        1           30        30   \n",
       "20459  20211212212591             5        1            0         0   \n",
       "20460  20211212212591             9        9            0         0   \n",
       "\n",
       "       TRTCOC_LN  TRTEC_LN  TRTHH_LN  TRTNOHH_LN  TRTOHH_LN  ...  WUINTERACT  \\\n",
       "0              0        -1        -1          -1         -1  ...           1   \n",
       "1              0        -1        -1          -1         -1  ...           1   \n",
       "2              0        -1        -1          -1         -1  ...           1   \n",
       "3              0        -1        -1          -1         -1  ...           1   \n",
       "4              0        -1        -1          -1         -1  ...           1   \n",
       "...          ...       ...       ...         ...        ...  ...         ...   \n",
       "20456          0        -1        20          -1         20  ...           1   \n",
       "20457          0        -1         0          -1          0  ...           1   \n",
       "20458          0        -1        30          -1         30  ...           1   \n",
       "20459          0        -1         0          -1          0  ...           1   \n",
       "20460          0        -1         0          -1          0  ...           1   \n",
       "\n",
       "       WUMEANING  WUPAIN  WUPNORD  WUSAD  WUSADORD  WUSTRESS  WUSTRORD  \\\n",
       "0              5       6        5      0         4         2         2   \n",
       "1              4       5        5      1         4         5         2   \n",
       "2              5       4        5      0         4         2         2   \n",
       "3              3       0        5      0         2         1         1   \n",
       "4              5       0        5      0         2         4         1   \n",
       "...          ...     ...      ...    ...       ...       ...       ...   \n",
       "20456          6       2        5      3         4         2         3   \n",
       "20457          1       1        5      2         4         3         3   \n",
       "20458          6       4        2      0         1         0         5   \n",
       "20459          6       4        2      0         1         0         5   \n",
       "20460          6       4        2      0         1         0         5   \n",
       "\n",
       "       WUTIRED  WUTRDORD  \n",
       "0            5         3  \n",
       "1            3         3  \n",
       "2            3         3  \n",
       "3            0         3  \n",
       "4            0         3  \n",
       "...        ...       ...  \n",
       "20456        5         1  \n",
       "20457        3         1  \n",
       "20458        0         4  \n",
       "20459        0         4  \n",
       "20460        0         4  \n",
       "\n",
       "[20461 rows x 44 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "atusact_df = pd.read_csv('/Users/ruchiraray/Documents/UT Austin/Soc-HHR/atusact-2021/atusact_2021.csv',header=0)\n",
    "# atussum_df = pd.read_csv('/Users/ruchiraray/Documents/UT Austin/Soc-HHR/atussum-2021/atussum_2021.csv')\n",
    "\n",
    "\n",
    "# Merge the filtered atussum_df with atusact_df on TUCASEID\n",
    "atusact_subset_df = pd.merge(atusact_df, atus_summary_df[['TUCASEID']], on='TUCASEID', how='inner')\n",
    "\n",
    "wb = pd.read_csv('/Users/ruchiraray/Documents/UT Austin/Soc-HHR/wbact-2021/wbact_2021.csv')\n",
    "\n",
    "# Merge the datasets on TUCASEID and TUACTIVITY_N\n",
    "merged_data = pd.merge(atusact_subset_df, wb, on=['TUCASEID', 'TUACTIVITY_N'])\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find the Mean and Variance in Happiness and Meaningfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filtered_data = merged_data[(merged_data['WUHAPPY'] >= 0) & (merged_data['WUMEANING'] >= 0)]\n",
    "\n",
    "# Group by 'TRCODE' and calculate the mean for 'WUHAPPY' and 'WUMEANING'\n",
    "mean_values = filtered_data.groupby('TRCODE')[['WUHAPPY', 'WUMEANING']].mean().reset_index()\n",
    "\n",
    "\n",
    "activity_time = pd.read_csv('/Users/ruchiraray/Documents/UT Austin/Soc-HHR/BEHAVIOR1kData/survey_analysis/activity_time_2021_mid.csv')\n",
    "# activity_time=atus_summary_df\n",
    "\n",
    "# Ensure the TRCODE and Activity Code are of the same type, adjust as necessary\n",
    "activity_time['Activity Code'] = activity_time['Activity Code'].astype(int)\n",
    "\n",
    "# Merge the DataFrames on the appropriate columns\n",
    "merged_data_with_activities = pd.merge(mean_values, activity_time, left_on='TRCODE', right_on='Activity Code')\n",
    "\n",
    "# Select and rename the columns as needed\n",
    "final_data = merged_data_with_activities[['TRCODE', 'WUHAPPY', 'WUMEANING', 'Activity']]\n",
    "\n",
    "final_data.to_csv(\"wb_2021_.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     TRCODE  Mean_WUHAPPY  Mean_WUMEANING  var_WUHAPPY  var_WUMEANING  \\\n",
      "0     10301      3.647541        4.049180     3.684663       4.262024   \n",
      "1     10399      0.000000        0.000000          NaN            NaN   \n",
      "2     20101      3.888889        3.884444     3.199208       3.768354   \n",
      "3     20102      3.968652        3.742947     2.565052       3.977741   \n",
      "4     20103      4.640000        4.840000     1.906667       2.306667   \n",
      "..      ...           ...             ...          ...            ...   \n",
      "270  181601      4.285714        4.142857     4.238095       2.476190   \n",
      "271  181801      4.142857        2.857143     1.809524       3.476190   \n",
      "272  189999      4.592593        3.888889     2.359189       5.345912   \n",
      "273  500101      3.972727        4.172727     3.421268       4.107506   \n",
      "274  500103      4.789474        5.105263     2.397661       1.321637   \n",
      "\n",
      "                                      Activity  \n",
      "0                     Health-related self care  \n",
      "1                           Self care, n.e.c.*  \n",
      "2                            Interior cleaning  \n",
      "3                                      Laundry  \n",
      "4    Sewing, repairing, & maintaining textiles  \n",
      "..                                         ...  \n",
      "270              Travel related to phone calls  \n",
      "271   Security procedures related to traveling  \n",
      "272                         Traveling, n.e.c.*  \n",
      "273            Insufficient detail in verbatim  \n",
      "274              Missing travel or destination  \n",
      "\n",
      "[275 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7b/w2c_xdts2nd4b407r_j90r9h0000gn/T/ipykernel_24459/3958928541.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.rename(columns={'WUHAPPY': 'Mean_WUHAPPY', 'WUMEANING': 'Mean_WUMEANING'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "activity_time = pd.read_csv('activity_time_2021_.csv')\n",
    "wb = merged_data\n",
    "\n",
    "# Ensure the TRCODE and Activity Code are of the same type\n",
    "activity_time['Activity Code'] = activity_time['Activity Code'].astype(int)\n",
    "\n",
    "# Filter out rows with negative WUHAPPY or WUMEANING\n",
    "filtered_data = wb[(wb['WUHAPPY'] >= 0) & (wb['WUMEANING'] >= 0)]\n",
    "\n",
    "# Group by 'TRCODE' and calculate the mean and variance for 'WUHAPPY' and 'WUMEANING'\n",
    "mean_values = filtered_data.groupby('TRCODE')[['WUHAPPY', 'WUMEANING']].mean().reset_index()\n",
    "variance_values = filtered_data.groupby('TRCODE')[['WUHAPPY', 'WUMEANING']].var().reset_index()\n",
    "\n",
    "# Rename the variance columns to avoid confusion\n",
    "variance_values.rename(columns={'WUHAPPY': 'var_WUHAPPY', 'WUMEANING': 'var_WUMEANING'}, inplace=True)\n",
    "\n",
    "# Merge the mean and variance data\n",
    "mean_variance_data = pd.merge(mean_values, variance_values, on='TRCODE')\n",
    "\n",
    "# Merge the mean_variance_data with the activity_time data\n",
    "merged_data_with_activities = pd.merge(mean_variance_data, activity_time, left_on='TRCODE', right_on='Activity Code')\n",
    "\n",
    "# Select and rename the columns as needed\n",
    "final_data = merged_data_with_activities[['TRCODE', 'WUHAPPY', 'WUMEANING', 'var_WUHAPPY', 'var_WUMEANING', 'Activity']]\n",
    "final_data.rename(columns={'WUHAPPY': 'Mean_WUHAPPY', 'WUMEANING': 'Mean_WUMEANING'}, inplace=True)\n",
    "\n",
    "# Save the final data to a CSV file\n",
    "final_data.to_csv('wb_2021_.csv', index=False)\n",
    "\n",
    "# Output the final dataframe for verification\n",
    "print(final_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRCODE</th>\n",
       "      <th>var_WUHAPPY</th>\n",
       "      <th>var_WUMEANING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10301</td>\n",
       "      <td>3.684663</td>\n",
       "      <td>4.262024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20101</td>\n",
       "      <td>3.199208</td>\n",
       "      <td>3.768354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20102</td>\n",
       "      <td>2.565052</td>\n",
       "      <td>3.977741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20103</td>\n",
       "      <td>1.906667</td>\n",
       "      <td>2.306667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>181601</td>\n",
       "      <td>4.238095</td>\n",
       "      <td>2.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>181801</td>\n",
       "      <td>1.809524</td>\n",
       "      <td>3.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>189999</td>\n",
       "      <td>2.359189</td>\n",
       "      <td>5.345912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>500101</td>\n",
       "      <td>3.421268</td>\n",
       "      <td>4.107506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>500103</td>\n",
       "      <td>2.397661</td>\n",
       "      <td>1.321637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TRCODE  var_WUHAPPY  var_WUMEANING\n",
       "0     10301     3.684663       4.262024\n",
       "1     10399          NaN            NaN\n",
       "2     20101     3.199208       3.768354\n",
       "3     20102     2.565052       3.977741\n",
       "4     20103     1.906667       2.306667\n",
       "..      ...          ...            ...\n",
       "274  181601     4.238095       2.476190\n",
       "275  181801     1.809524       3.476190\n",
       "276  189999     2.359189       5.345912\n",
       "277  500101     3.421268       4.107506\n",
       "278  500103     2.397661       1.321637\n",
       "\n",
       "[279 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
